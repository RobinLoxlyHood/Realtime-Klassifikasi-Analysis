{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HI4ujUlnZah4"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "import multiprocessing\n",
        "import io\n",
        "# import gensim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "# import keras\n",
        "from sklearn.model_selection import KFold # import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "# from tensorflow import keras\n",
        "# from keras.models import Sequential\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from keras.callbacks import ModelCheckpoint\n",
        "# from keras.preprocessing.text import Tokenizer\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Embedding\n",
        "# from keras.layers import Dense, Activation, Embedding, LSTM, Bidirectional, Dropout, GRU\n",
        "# from keras import regularizers\n",
        "# from tensorflow.keras.utils import to_categorical\n",
        "# from keras.models import load_model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import vektor_tfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import metrics\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from collections import defaultdict\n",
        "from datetime import timedelta\n",
        "# from gensim.models import word2vec\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from varname import nameof\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtyarzfKc1DO"
      },
      "source": [
        "#2.Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "zg_Jvs3Qa3pq"
      },
      "outputs": [],
      "source": [
        "#simpan path dataset\n",
        "path_data_sentimen = \"data_scraping_kota_TGL.csv\"\n",
        "data_sentimen = pd.read_csv(path_data_sentimen, sep=\",\", header=[0], encoding=\"UTF-8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>date</th>\n",
              "      <th>username</th>\n",
              "      <th>tweet</th>\n",
              "      <th>wisata_hiburan</th>\n",
              "      <th>pendidikan</th>\n",
              "      <th>fasilitas_layanan_publik</th>\n",
              "      <th>kuliner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>09/12/2021 23:11</td>\n",
              "      <td>BsiWahyudi</td>\n",
              "      <td>Wisuda Universitas BSI Kampus Kabupaten Banyum...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>09/12/2021 20:44</td>\n",
              "      <td>PPPLarangan</td>\n",
              "      <td>(03/12/2021)  Mengikuti kegiatan bersih pantai...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>09/12/2021 19:46</td>\n",
              "      <td>AdvFeryAjah</td>\n",
              "      <td>@infoplntegal Selamat malam , mohon di tindak ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>09/12/2021 19:27</td>\n",
              "      <td>tegalfess</td>\n",
              "      <td>[TF] info banjir daerah tegal kota dong lurr, ...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>09/12/2021 14:58</td>\n",
              "      <td>detikcom</td>\n",
              "      <td>Pemasangan portal di jalan masuk Alun-alun Kot...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0              date     username  \\\n",
              "0           0  09/12/2021 23:11   BsiWahyudi   \n",
              "1           1  09/12/2021 20:44  PPPLarangan   \n",
              "2           2  09/12/2021 19:46  AdvFeryAjah   \n",
              "3           3  09/12/2021 19:27    tegalfess   \n",
              "4           4  09/12/2021 14:58     detikcom   \n",
              "\n",
              "                                               tweet  wisata_hiburan  \\\n",
              "0  Wisuda Universitas BSI Kampus Kabupaten Banyum...              -1   \n",
              "1  (03/12/2021)  Mengikuti kegiatan bersih pantai...              -1   \n",
              "2  @infoplntegal Selamat malam , mohon di tindak ...              -1   \n",
              "3  [TF] info banjir daerah tegal kota dong lurr, ...              -1   \n",
              "4  Pemasangan portal di jalan masuk Alun-alun Kot...              -1   \n",
              "\n",
              "   pendidikan  fasilitas_layanan_publik  kuliner  \n",
              "0           1                        -1       -1  \n",
              "1          -1                         1       -1  \n",
              "2          -1                         0       -1  \n",
              "3          -1                        -1        1  \n",
              "4          -1                         0       -1  "
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_sentimen.columns = ['Unnamed: 0', 'date', 'username', 'tweet', 'wisata_hiburan', 'pendidikan', 'fasilitas_layanan_publik', 'kuliner']\n",
        "data_sentimen.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHd8zoL5ePma"
      },
      "source": [
        "#3.Implementasi Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LcNrqHr50MeU"
      },
      "outputs": [],
      "source": [
        "#menyimpan tweet. (tipe data series pandas)\n",
        "data_content = data_sentimen['tweet']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNzxbK5i0Pcu"
      },
      "source": [
        "##3.1. Casefolding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALc2jvPU0Ueb",
        "outputId": "efc3b67b-8413-4447-92b0-d50181c06d2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    wisuda universitas bsi kampus kabupaten banyum...\n",
              "1    (03/12/2021)  mengikuti kegiatan bersih pantai...\n",
              "2    @infoplntegal selamat malam , mohon di tindak ...\n",
              "3    [tf] info banjir daerah tegal kota dong lurr, ...\n",
              "4    pemasangan portal di jalan masuk alun-alun kot...\n",
              "Name: tweet, dtype: object"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# casefolding\n",
        "data_casefolding = data_content.str.lower()\n",
        "data_casefolding.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A0nfLDO0Xgy"
      },
      "source": [
        "##3.2. Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pVsCbmmq0cuS"
      },
      "outputs": [],
      "source": [
        "#filtering\n",
        "\n",
        "#url\n",
        "filtering_url = [re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", tweet) for tweet in data_casefolding]\n",
        "#cont\n",
        "filtering_cont = [re.sub(r'\\(cont\\)',\" \", tweet)for tweet in filtering_url]\n",
        "#punctuatuion\n",
        "filtering_punctuation = [re.sub('[!\"”#$%&’()*+,-./:;<=>?@[\\]^_`{|}~]', ' ', tweet) for tweet in filtering_cont]  #hapus simbol'[!#?,.:\";@()-_/\\']'\n",
        "#  hapus #tagger\n",
        "filtering_tagger = [re.sub(r'#([^\\s]+)', '', tweet) for tweet in filtering_punctuation]\n",
        "#numeric\n",
        "filtering_numeric = [re.sub(r'\\d+', ' ', tweet) for tweet in filtering_tagger]\n",
        "\n",
        "# # filtering RT , @ dan #\n",
        "# fungsi_clen_rt = lambda x: re.compile('\\#').sub('', re.compile('rt @').sub('@', x, count=1).strip())\n",
        "# clean = [fungsi_clen_rt for tweet in filtering_numeric]\n",
        "\n",
        "data_filtering = pd.Series(filtering_numeric)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZ7vaeLzXE8_",
        "outputId": "521e04d8-fdaf-4733-d8a3-1a8f328f5473"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      wisuda universitas bsi kampus kabupaten banyum...\n",
              "1               mengikuti kegiatan bersih pantai yang...\n",
              "2       infoplntegal selamat malam   mohon di tindak ...\n",
              "3       tf  info banjir daerah tegal kota dong lurr  ...\n",
              "4      pemasangan portal di jalan masuk alun alun kot...\n",
              "                             ...                        \n",
              "375    sekda  kota tegal johardi mempersilakan jika a...\n",
              "376     tegalfess mie ayam solo baru ini yg tegal kot...\n",
              "377    senin        ratih  m  luhkan kota tegal  di m...\n",
              "378     tf  saran sate taichan di tegal kota yg enak ...\n",
              "379     tf  gaes  rekomendasiin mie ayam enak di tega...\n",
              "Length: 380, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts2lHtue0kAk"
      },
      "source": [
        "## 3.3. Tokenisasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2sooKgeb0o9R"
      },
      "outputs": [],
      "source": [
        "# #tokenize\n",
        "tknzr = TweetTokenizer()\n",
        "data_tokenize = [tknzr.tokenize(tweet) for tweet in data_filtering]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1KQ2I_xXKTS",
        "outputId": "2f52fb8f-9eff-46c6-c437-172a0dbfc97a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['wisuda',\n",
              "  'universitas',\n",
              "  'bsi',\n",
              "  'kampus',\n",
              "  'kabupaten',\n",
              "  'banyumas',\n",
              "  'ke',\n",
              "  'amp',\n",
              "  'kampus',\n",
              "  'kota',\n",
              "  'tegal',\n",
              "  'ke',\n",
              "  'java',\n",
              "  'heritage',\n",
              "  'hotel',\n",
              "  'purwokerto'],\n",
              " ['mengikuti',\n",
              "  'kegiatan',\n",
              "  'bersih',\n",
              "  'pantai',\n",
              "  'yang',\n",
              "  'diselenggarakan',\n",
              "  'lanal',\n",
              "  'tegal',\n",
              "  'di',\n",
              "  'pantai',\n",
              "  'alam',\n",
              "  'indah',\n",
              "  'kota',\n",
              "  'tegal',\n",
              "  'kegiatan',\n",
              "  'ini',\n",
              "  'diikuti',\n",
              "  'oleh',\n",
              "  'berbagai',\n",
              "  'instansi',\n",
              "  'terkait',\n",
              "  'di',\n",
              "  'kota',\n",
              "  'tegal',\n",
              "  'dan',\n",
              "  'sekitarnya',\n",
              "  'dkpjateng',\n",
              "  'djpt',\n",
              "  'kkp'],\n",
              " ['infoplntegal',\n",
              "  'selamat',\n",
              "  'malam',\n",
              "  'mohon',\n",
              "  'di',\n",
              "  'tindak',\n",
              "  'lanjuti',\n",
              "  'di',\n",
              "  'daerah',\n",
              "  'saya',\n",
              "  'dari',\n",
              "  'jam',\n",
              "  'wib',\n",
              "  'mati',\n",
              "  'listrik',\n",
              "  'sampai',\n",
              "  'sekarang',\n",
              "  'belum',\n",
              "  'menyala',\n",
              "  'alamat',\n",
              "  'di',\n",
              "  'jl',\n",
              "  'drcipto',\n",
              "  'mangunkusumo',\n",
              "  'kaligansa',\n",
              "  'kecamatan',\n",
              "  'margadana',\n",
              "  'kota',\n",
              "  'tegal'],\n",
              " ['tf',\n",
              "  'info',\n",
              "  'banjir',\n",
              "  'daerah',\n",
              "  'tegal',\n",
              "  'kota',\n",
              "  'dong',\n",
              "  'lurr',\n",
              "  'kayong',\n",
              "  'pgn',\n",
              "  'seblak',\n",
              "  'kie',\n",
              "  'makasii'],\n",
              " ['pemasangan',\n",
              "  'portal',\n",
              "  'di',\n",
              "  'jalan',\n",
              "  'masuk',\n",
              "  'alun',\n",
              "  'alun',\n",
              "  'kota',\n",
              "  'tegal',\n",
              "  'diprotes',\n",
              "  'pedagang',\n",
              "  'wali',\n",
              "  'kota',\n",
              "  'tegal',\n",
              "  'deddy',\n",
              "  'yon',\n",
              "  'suriyono',\n",
              "  'membeberkan',\n",
              "  'alasan',\n",
              "  'dari',\n",
              "  'penutupan',\n",
              "  'jalan',\n",
              "  'tersebut']]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_tokenize[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZk9kLGa0sSB"
      },
      "source": [
        "##3.4. Konversi Slangword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXnSpBqGeGyb",
        "outputId": "f7d3a51b-b661-47dc-83ba-903788a4746d"
      },
      "outputs": [],
      "source": [
        "#slang word\n",
        "path_dataslang = open(\"kamus kata baku-clear (1).csv\")\n",
        "dataslang = pd.read_csv(path_dataslang, encoding = 'utf-8', header=None, sep=\";\")\n",
        "\n",
        "def replaceSlang(word):\n",
        "  if word in list(dataslang[0]):\n",
        "    indexslang = list(dataslang[0]).index(word)\n",
        "    return dataslang[1][indexslang]\n",
        "  else:\n",
        "    return word\n",
        "\n",
        "data_formal = []\n",
        "for data in data_tokenize:\n",
        "  data_clean = [replaceSlang(word) for word in data]\n",
        "  data_formal.append(data_clean)\n",
        "len_data_formal = len(data_formal)\n",
        "# print(data_formal)\n",
        "# len_data_formal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp6NXGRerCK4"
      },
      "source": [
        "## 3.5. Stopword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogP3tGEHggHJ",
        "outputId": "8c1aa601-2cc6-4988-c125-40a863c9658c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\novit\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "default_stop_words = nltk.corpus.stopwords.words('indonesian')\n",
        "stopwords = set(default_stop_words)\n",
        "\n",
        "def removeStopWords(line, stopwords):\n",
        "  words = []\n",
        "  for word in line:  \n",
        "    word=str(word)\n",
        "    word = word.strip()\n",
        "    if word not in stopwords and word != \"\" and word != \"&\":\n",
        "      words.append(word)\n",
        "\n",
        "  return words\n",
        "reviews = [removeStopWords(line,stopwords) for line in data_formal]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPbyKfzzeVwC"
      },
      "outputs": [],
      "source": [
        "# pickle.dump(reviews, open(\"/content/drive/My Drive/Thesis/Tesis/program/data/model/NVB/reviews.pickle\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DYTxiKe1Qv0"
      },
      "source": [
        "# 4.Implementasi Naive Bayes (Klasifikasi Aspek)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fa49U0myBhg"
      },
      "source": [
        "## 4.1.pembuatan vector kata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fJyFVF8w1UX4"
      },
      "outputs": [],
      "source": [
        "# pembuatan vector kata\n",
        "# reviews = pickle.load(open(\"/content/drive/My Drive/Thesis/Tesis/program/data/model/NVB/reviews.pickle\", \"rb\"))\n",
        "vectorizer = TfidfVectorizer()\n",
        "reviews2 = [\" \".join(r) for r in reviews]\n",
        "vektor_tfidf = vectorizer.fit_transform(reviews2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Aspek Wisata"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "class READ_DATA:\n",
        "      aspek = ''\n",
        "      vektor_tfidf = ''\n",
        "      data_sentimen_wisata_hiburan = \"\"\n",
        "      data_sentimen_pendidikan = \"\" \n",
        "      data_sentimen_fasilitas_layanan_publik = \"\"\n",
        "      data_sentimen_kuliner = \"\" \n",
        "      # data_sentimen_kontinuitas = \"\"\n",
        "      def __init__(self, data_sentimen, vektor_tfidf):\n",
        "          self.data_sentimen_wisata_hiburan = data_sentimen['wisata_hiburan']\n",
        "          self.data_sentimen_pendidikan = data_sentimen['pendidikan']\n",
        "          self.data_sentimen_fasilitas_layanan_publik = data_sentimen['fasilitas_layanan_publik']\n",
        "          self.data_sentimen_kuliner = data_sentimen['kuliner']\n",
        "          self.vektor_tfidf = vektor_tfidf\n",
        "\n",
        "      def get_data_sentimen(self, aspek):\n",
        "          data_sentimen= getattr(self, f'data_sentimen_{aspek}')\n",
        "          data_sentimen_list = data_sentimen.to_list()\n",
        "          # print(type(data_sentimen_list[0]))\n",
        "\n",
        "          #filter hapus data yang tidak memiliki sentimen (-1)\n",
        "          x_, y_ = [],[]    \n",
        "          for i, j in zip(vektor_tfidf, data_sentimen_list):\n",
        "              if j != -1:\n",
        "                  x_.append(i)\n",
        "                  y_.append(j)\n",
        "          return x_, y_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "Tchu-uO0eBdT"
      },
      "outputs": [],
      "source": [
        "# Ubah kategori\n",
        "read_data = READ_DATA(data_sentimen, vektor_tfidf)\n",
        "x_content_sentimen_NVB, y_label_sentimen_NVB = read_data.get_data_sentimen('wisata_hiburan')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.utils.multiclass import unique_labels\n",
        "unique_labels(y_label_sentimen_NVB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x_content_sentimen_NVB, y_label_sentimen_NVB, test_size=0.2)#, shuffle=True)\n",
        "# nama = \"Model_Sentimen_Wisata_Hiburan\"\n",
        "# y_train = np.array(y_train)\n",
        "# y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected 2D array, got 1D array instead:\narray=[<1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 26 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 3 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 20 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 25 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 28 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 15 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 3 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 26 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 29 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 18 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 23 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 17 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 4 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[78], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimblearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mover_sampling\u001b[39;00m \u001b[39mimport\u001b[39;00m ADASYN\n\u001b[1;32m----> 3\u001b[0m X_resampled, y_resampled \u001b[39m=\u001b[39m ADASYN()\u001b[39m.\u001b[39;49mfit_resample(X_train, y_train)\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\base.py:203\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \n\u001b[0;32m    184\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[39m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 203\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_resample(X, y)\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\base.py:82\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     80\u001b[0m check_classification_targets(y)\n\u001b[0;32m     81\u001b[0m arrays_transformer \u001b[39m=\u001b[39m ArraysTransformer(X, y)\n\u001b[1;32m---> 82\u001b[0m X, y, binarize_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[0;32m     84\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy_ \u001b[39m=\u001b[39m check_sampling_strategy(\n\u001b[0;32m     85\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msampling_strategy, y, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampling_type\n\u001b[0;32m     86\u001b[0m )\n\u001b[0;32m     88\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_resample(X, y)\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imblearn\\base.py:156\u001b[0m, in \u001b[0;36mBaseSampler._check_X_y\u001b[1;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[0;32m    154\u001b[0m     accept_sparse \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mcsr\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    155\u001b[0m y, binarize_y \u001b[39m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 156\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, reset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49maccept_sparse)\n\u001b[0;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m X, y, binarize_y\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    552\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[1;32m-> 1104\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1105\u001b[0m     X,\n\u001b[0;32m   1106\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1107\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1108\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1109\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1110\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1111\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1112\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1113\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1114\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1115\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1116\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1117\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1118\u001b[0m )\n\u001b[0;32m   1120\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1122\u001b[0m check_consistent_length(X, y)\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:900\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 900\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    901\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    902\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    905\u001b[0m         )\n\u001b[0;32m    907\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    908\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    909\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    910\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[<1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 26 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 3 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 20 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 25 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 28 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 15 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 3 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 26 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 29 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 18 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 23 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 17 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 4 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "X_resampled, y_resampled = ADASYN().fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected 2D array, got 1D array instead:\narray=[<1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 26 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 3 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 20 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 25 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 28 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 15 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 3 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 26 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 29 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 18 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 23 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 17 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 4 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[79], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m metrics\n\u001b[0;32m      2\u001b[0m clf \u001b[39m=\u001b[39m MultinomialNB()\n\u001b[1;32m----> 3\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      4\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_train)\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAkurasi : \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(clf\u001b[39m.\u001b[39mscore(X_train, y_train)))\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\naive_bayes.py:747\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \n\u001b[0;32m    729\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    744\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    745\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 747\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_X_y(X, y)\n\u001b[0;32m    748\u001b[0m _, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m    750\u001b[0m labelbin \u001b[39m=\u001b[39m LabelBinarizer()\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\naive_bayes.py:581\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_X_y\u001b[39m(\u001b[39mself\u001b[39m, X, y, reset\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    580\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49mreset)\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    552\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 554\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1102\u001b[0m     )\n\u001b[1;32m-> 1104\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1105\u001b[0m     X,\n\u001b[0;32m   1106\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1107\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1108\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1109\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1110\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1111\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1112\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1113\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1114\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1115\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1116\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1117\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1118\u001b[0m )\n\u001b[0;32m   1120\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1122\u001b[0m check_consistent_length(X, y)\n",
            "File \u001b[1;32mc:\\Users\\novit\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:900\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 900\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    901\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    902\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    905\u001b[0m         )\n\u001b[0;32m    907\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    908\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    909\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    910\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[<1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 26 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 3 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 20 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 25 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 28 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 15 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 13 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 3 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 26 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 29 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 14 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 10 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 6 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 18 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 23 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 9 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 19 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 17 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 11 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 4 stored elements in Compressed Sparse Row format>\n <1x2023 sparse matrix of type '<class 'numpy.float64'>'\n \twith 22 stored elements in Compressed Sparse Row format>].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "clf = MultinomialNB()\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_train)\n",
        "print(\"Akurasi : \"+str(clf.score(X_train, y_train)))\n",
        "\n",
        "print(\"Precission : \"+str(metrics.precision_score(y_train, y_pred, labels=[0,1], average='macro')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save model\n",
        "# model_nvb = 'vektor_tfidf_sentimen_integritas_nvb.sav'\n",
        "pickle.dump(clf, open('model/vektor_tfidf_{}_nvb.pkl'.format(nama), 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------\n",
            "confusion matrix : Model_Aspek_Wisata_Hiburan\n",
            "--------------------------------------------- \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       1.00      0.86      0.93        95\n",
            "           0       0.12      1.00      0.22         1\n",
            "           1       0.67      0.89      0.76        18\n",
            "\n",
            "    accuracy                           0.87       114\n",
            "   macro avg       0.60      0.92      0.64       114\n",
            "weighted avg       0.94      0.87      0.89       114\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = pickle.load(open('model/vektor_tfidf_'+str(nama)+'_nvb.pkl','rb'))\n",
        "pred_y_ = model.predict(X_test)\n",
        "label_test = y_test\n",
        "# result = model.score(X_test, y_test)\n",
        "print('\\n'+'-'*45)\n",
        "print('confusion matrix : ' + str(nama))\n",
        "print('-'*45,'\\n')\n",
        "print(classification_report(label_test, pred_y_, labels=[-1, 0, 1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ-iah3PJpAs"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(vektor_vektor_tfidf, sentimen_kontinuitas, test_size=0.2)\n",
        "nama_sentimen = nameof(sentimen_kontinuitas)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zrmqNrMOQwi",
        "outputId": "af1f7901-e5d9-4578-d7a4-69f90ba248df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n"
          ]
        }
      ],
      "source": [
        "# Cross-validasi\n",
        "kf = StratifiedKFold(n_splits=2)#,shuffle=True, random_state=None) # Define the split - into 5 folds \n",
        "kf.get_n_splits(X_train) # returns the number of splitting iterations in the cross-validator\n",
        "print(kf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7aDUeyFGCv1"
      },
      "source": [
        "# 5.Klasifikasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgJBvGpM7qrZ"
      },
      "outputs": [],
      "source": [
        "def hitung_score_multiclass(y_test_sentimen, y_pred):\n",
        "    # cm = metrics.confusion_matrix(y_test_sentimen, y_pred, labels=[-1,0,-1])\n",
        "    mcm = multilabel_confusion_matrix(y_test_sentimen, y_pred, labels=[-1,0,1])\n",
        "    # print(cm)\n",
        "    print('\\n'+'-'*50)\n",
        "    print('confusion matrix : ' + str(nama_sentimen))\n",
        "    print('-'*50)\n",
        "    print(plot(label_asli,pred_y_nvb),'\\n')\n",
        "    tn = mcm[:, 0, 0]\n",
        "    tp = mcm[:, 1, 1]\n",
        "    fn = mcm[:, 1, 0]\n",
        "    fp = mcm[:, 0, 1]\n",
        "    print(\"TP : \" + str(tp),\n",
        "          \"TN : \" +str(tn),\n",
        "          \"FP : \" +str(fp),\n",
        "          \"FN : \" +str(fn),'\\n')\n",
        "    acc = accuracy_score(y_test_sentimen, y_pred)\n",
        "    prec_mi = precision_score(y_test_sentimen, y_pred, average='micro')\n",
        "    prec_ma = precision_score(y_test_sentimen, y_pred, average='macro')\n",
        "    recc_mi = recall_score(y_test_sentimen, y_pred, average='micro')\n",
        "    recc_ma = recall_score(y_test_sentimen, y_pred, average='macro')\n",
        "    f1_mi = f1_score(y_test_sentimen, y_pred, average='micro')\n",
        "    f1_ma = f1_score(y_test_sentimen, y_pred, average='macro')\n",
        "\n",
        "    return  round(acc,4) , round(prec_mi,4), round(recc_mi,4), round(f1_mi,4), round(prec_ma,4), round(recc_ma,4), round(f1_ma,4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5EfauMLatZM"
      },
      "outputs": [],
      "source": [
        "def plot(test_y, pred_y):\n",
        "  # labels = unique_labels(label_integritas)\n",
        "  labels = (-1,0,1)\n",
        "  # print(labels)\n",
        "  column = [f'Prediksi {label}' for label in labels]\n",
        "  indeces = [f'Actual {label}' for label in labels]\n",
        "  table = pd.DataFrame(confusion_matrix(test_y, pred_y),\n",
        "                       columns = column, index = indeces)\n",
        "  return table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WC6Bv1GhdM-",
        "outputId": "3690f297-bcc6-42a0-eedf-8b230d300a3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1,  0,  1])"
            ]
          },
          "execution_count": 363,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = unique_labels(y_test)\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nu3SgDUOc-N"
      },
      "source": [
        "## 5.1.Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SS3vD4y4f9g",
        "outputId": "7cd699ba-4559-49d3-942e-43c64323bf28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "confusion matrix : sentimen_kontinuitas\n",
            "--------------------------------------------------\n",
            "           Prediksi -1  Prediksi 0  Prediksi 1\n",
            "Actual -1          535           0           0\n",
            "Actual 0             1           0           0\n",
            "Actual 1             2           0           0 \n",
            "\n",
            "TP : [535   0   0] TN : [  0 537 536] FP : [3 0 0] FN : [0 1 2] \n",
            "\n",
            "\u001b[1m\u001b[31mScore fold ke-1\u001b[0m \n",
            " acc training  : 0.9944% \n",
            " Prec Micro  : 0.9944% \n",
            " Prec Macro  : 0.9944% \n",
            " recc Micro  : 0.9944% \n",
            " recc Macro  : 0.3315% \n",
            " f_1 Micro  : 0.3333% \n",
            " f_1 Macro  : 0.3324% \n",
            "\n",
            "\n",
            "--------------------------------------------------\n",
            "confusion matrix : sentimen_kontinuitas\n",
            "--------------------------------------------------\n",
            "           Prediksi -1  Prediksi 0  Prediksi 1\n",
            "Actual -1          534           0           0\n",
            "Actual 0             1           0           0\n",
            "Actual 1             3           0           0 \n",
            "\n",
            "TP : [534   0   0] TN : [  0 537 535] FP : [4 0 0] FN : [0 1 3] \n",
            "\n",
            "\u001b[1m\u001b[31mScore fold ke-2\u001b[0m \n",
            " acc training  : 0.9926% \n",
            " Prec Micro  : 0.9926% \n",
            " Prec Macro  : 0.9926% \n",
            " recc Micro  : 0.9926% \n",
            " recc Macro  : 0.3309% \n",
            " f_1 Micro  : 0.3333% \n",
            " f_1 Macro  : 0.3321% \n",
            "\n",
            "\u001b[1m\u001b[31mRata-rata Akurasi NVB : \u001b[0m\n",
            " acc training: 0.9935% \n",
            " Prec Micro: 0.9935% \n",
            " Prec Macro: 0.9935% \n",
            " Recall Micro: 0.9935% \n",
            " Recall Macro: 0.33120000000000005% \n",
            " F1 Micro: 0.3333% \n",
            " F1 Macro: 0.33225% \n",
            "\n",
            "Fold-1 : 0.9944% Fold-2 : 0.9926%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "kf_nvb_number = 0\n",
        "akurasi_nvb_arr = []\n",
        "prec_nvb_arr_mi = []\n",
        "prec_nvb_arr_ma = []\n",
        "rec_nvb_arr_mi = []\n",
        "rec_nvb_arr_ma = []\n",
        "f1_nvb_arr_mi = []\n",
        "f1_nvb_arr_ma = []\n",
        "score = {\n",
        "    'Akurasi':[],\n",
        "    'Presisi_mi':[],\n",
        "    'Recall_mi':[],\n",
        "    'F1_mi':[],\n",
        "    'Presisi_ma':[],\n",
        "    'Recall_ma':[],\n",
        "    'F1_ma':[]\n",
        "}\n",
        "index_fold = 1\n",
        "\n",
        "for train_aspek_nvb, test_aspek_nvb in kf.split(X_train, y_train):\n",
        "  X_train_aspek_nvb, X_test_aspek_nvb = X_train[train_aspek_nvb], X_train[test_aspek_nvb]\n",
        "  y_train_aspek_nvb, y_test_aspek_nvb = y_train[train_aspek_nvb], y_train[test_aspek_nvb]\n",
        " \n",
        "  kf_nvb_number += 1\n",
        " \n",
        "  # train model\n",
        "  clf = MultinomialNB()\n",
        "  clf.fit(X_train_aspek_nvb, y_train_aspek_nvb)\n",
        " \n",
        "  # save model\n",
        "  # model_nvb = 'vektor_tfidf_sentimen_integritas_nvb.sav'\n",
        "  pickle.dump(clf, open('/content/drive/My Drive/Thesis/Tesis/program/data/dataset/new_dataset/result_baru/nvb/'+str(nama_sentimen)+'/Fold'+str(index_fold)+'.pkl','wb'))\n",
        "\n",
        "  # pengujian\n",
        "  pred_y_nvb = clf.predict(X_test_aspek_nvb.toarray())\n",
        "  label_asli = y_test_aspek_nvb\n",
        "\n",
        "# confusion matrix\n",
        "  acc, prec_mi,prec_ma, recc_mi,recc_ma, f_1_mi,f_1_ma = hitung_score_multiclass(label_asli,pred_y_nvb)\n",
        "\n",
        "  score['Akurasi'].append(acc)\n",
        "  score['Presisi_mi'].append(prec_mi)\n",
        "  score['Presisi_ma'].append(prec_ma)\n",
        "  score['Recall_mi'].append(recc_mi)\n",
        "  score['Recall_ma'].append(recc_ma)\n",
        "  score['F1_mi'].append(f_1_mi)\n",
        "  score['F1_ma'].append(f_1_ma)\n",
        "\n",
        "  print(colored(\"Score fold ke-\" + str(index_fold), 'red', attrs=['bold']),'\\n',\n",
        "        'acc training  : ' + str(acc) + \"%\",'\\n',\n",
        "        'Prec Micro  : '+ str(prec_mi)+ \"%\", '\\n',\n",
        "        'Prec Macro  : '+ str(prec_ma)+ \"%\",'\\n',\n",
        "        'recc Micro  : '+ str(recc_mi)+ \"%\", '\\n',\n",
        "        'recc Macro  : '+ str(recc_ma)+ \"%\", '\\n',\n",
        "        'f_1 Micro  : '+ str(f_1_mi)+ \"%\",'\\n',\n",
        "        'f_1 Macro  : '+ str(f_1_ma)+ \"%\",'\\n')\n",
        "  \n",
        "  index_fold += 1\n",
        "from termcolor import colored\n",
        "print(colored(\"Rata-rata Akurasi NVB : \", 'red', attrs=['bold']))\n",
        "print(' acc training: ' + str(np.mean(score['Akurasi'])) + \"%\", '\\n',\n",
        "      'Prec Micro: ' + str(np.mean(score['Presisi_mi'])) + \"%\", '\\n',\n",
        "      'Prec Macro: ' + str(np.mean(score['Presisi_ma'])) + \"%\", '\\n',\n",
        "      'Recall Micro: ' + str(np.mean(score['Recall_mi'])) + \"%\", '\\n',\n",
        "      'Recall Macro: ' + str(np.mean(score['Recall_ma'])) + \"%\", '\\n',\n",
        "      'F1 Micro: ' + str(np.mean(score['F1_mi'])) + \"%\", '\\n',    \n",
        "      'F1 Macro: ' + str(np.mean(score['F1_ma'])) + \"%\", '\\n',\n",
        "      )\n",
        "print(\"Fold-1 : \" +str(score['Akurasi'][0]) + \"%\", \n",
        "      \"Fold-2 : \" + str(score['Akurasi'][1]) + \"%\")\n",
        "      # \"Fold-3 : \" + str(score['Akurasi'][2]) + \"%\",\n",
        "      # \"Fold-4 : \" + str(score['Akurasi'][3]) + \"%\", \n",
        "      # \"Fold-5 : \" + str(score['Akurasi'][4]) + \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7zTEaTcv5wt",
        "outputId": "c2847c44-00e5-463c-f199-830fc6a50316"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1])"
            ]
          },
          "execution_count": 365,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = unique_labels(pred_y_nvb)\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na6AlAamK_RS"
      },
      "source": [
        "## 5.2.Prediksi model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7LptzpZjHDP",
        "outputId": "e0472ede-fa2b-48dd-e198-8da0d8ca28cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pengujian sentimen_kontinuitas  :\n",
            "\n",
            "--------------------------------------------------\n",
            "confusion matrix : sentimen_kontinuitas\n",
            "--------------------------------------------------\n",
            "           Prediksi -1  Prediksi 0  Prediksi 1\n",
            "Actual -1          267           0           0\n",
            "Actual 0             1           0           0\n",
            "Actual 1             1           0           0 \n",
            "\n",
            "TP : [267   0   0] TN : [  0 268 268] FP : [2 0 0] FN : [0 1 1] \n",
            "\n",
            "\u001b[1m\u001b[31mModel terbaik fold ke-1\u001b[0m\n",
            " Akurasi  : 0.9926% \n",
            " Presisi Micro  : 0.9926% \n",
            " Presisi Macro  : 0.9926% \n",
            " Recall Micro  : 0.9926% \n",
            " Recall Macro  : 0.3309% \n",
            " F1 Micro  : 0.3333% \n",
            " F1 Macro  : 0.3321% \n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#Pengujian\n",
        "indeks=np.where(score[\"Akurasi\"]==np.amax(score['Akurasi']))[0]\n",
        "model = pickle.load(open('/content/drive/My Drive/Thesis/Tesis/program/data/dataset/new_dataset/result_baru/nvb/'+str(nama_sentimen)+'/Fold'+str(indeks[0]+1)+'.pkl','rb'))\n",
        "pred_y_nvb = model.predict(X_test)\n",
        "label_asli = y_test\n",
        "print(\"Pengujian \" + str(nama_sentimen),\" :\")\n",
        "acc, prec_mi,prec_ma, recc_mi,recc_ma, f_1_mi,f_1_ma = hitung_score_multiclass(label_asli,pred_y_nvb)\n",
        "print(colored('Model terbaik fold ke-'+str(indeks[0]+1), 'red', attrs=['bold']))\n",
        "print(' Akurasi  : ' + str(acc) + \"%\",'\\n',\n",
        "      'Presisi Micro  : '+ str(prec_mi)+ \"%\", '\\n',\n",
        "      'Presisi Macro  : '+ str(prec_ma)+ \"%\",'\\n',\n",
        "      'Recall Micro  : '+ str(recc_mi)+ \"%\", '\\n',\n",
        "      'Recall Macro  : '+ str(recc_ma)+ \"%\", '\\n',\n",
        "      'F1 Micro  : '+ str(f_1_mi)+ \"%\",'\\n',\n",
        "      'F1 Macro  : '+ str(f_1_ma)+ \"%\",'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLQW0dR8Km2K"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "60a61259bd30a4340a9723674d17cf7cb4e5e5fda8c8996df039e6704bf7359c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
